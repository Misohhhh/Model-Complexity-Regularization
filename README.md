# Model Complexity and Regularization

This project explores the impact of **model complexity**, the **bias-variance trade-off**, and **regularization techniques** in linear regression. We experiment with L1 (Lasso) and L2 (Ridge) regularization to understand how these techniques help manage overfitting.

## Overview
- **Gaussian Basis Functions**: Experimenting with model complexity using varying bases.
- **Bias-Variance Tradeoff**: Repeated experiments to identify the optimal complexity.
- **Regularization Techniques**: Implementation of L1 and L2 regularization with cross-validation to find the best regularization strength.

## Key Features
- **Synthetic Data**: Simulated data from non-linear functions.
- **Regularization Impact**: Comparison of L1 and L2 penalties on model performance.
- **Optimal Lambda Values**: Identified using **10-fold cross-validation**.

## How to Use
1. Clone the repository:
   ```bash
   git clone https://github.com/Misohhhh/Model-Complexity-Regularization.git
   cd Model-Complexity-Regularization
